---
import { type CollectionEntry, getCollection } from 'astro:content';
import BaseLayout from '@/components/layout/BaseLayout.astro';
import SimpleNotebookViewer from '@/components/notebook/SimpleNotebookViewer.astro';

export async function getStaticPaths() {
  const notebooks = await getCollection('notebooks');
  return notebooks.map((notebook) => ({
    params: { slug: notebook.slug },
    props: notebook,
  }));
}

type Props = CollectionEntry<'notebooks'>;

const notebook = Astro.props;

// ç¤ºä¾‹ notebook æ•°æ® - åœ¨å®é™…åº”ç”¨ä¸­ä¼šä» notebook æ–‡ä»¶è§£æ
const sampleNotebookCells = [
  {
    type: 'markdown' as const,
    source: `# ${notebook.data.title}

æœ¬ç¬”è®°å±•ç¤ºäº† RLHF (Reinforcement Learning from Human Feedback) è®­ç»ƒè¿‡ç¨‹çš„è¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œç»“æœè¯„ä¼°ã€‚

## å®éªŒæ¦‚è¿°

- **æ¨¡å‹**: GPT-2 (124M å‚æ•°)
- **æ•°æ®é›†**: Anthropic HH-RLHF æ•°æ®é›†
- **è®­ç»ƒæ­¥æ•°**: 1000 steps
- **å­¦ä¹ ç‡**: 3e-5`,
    executionCount: null
  },
  {
    type: 'code' as const,
    source: `import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch
import wandb

# è®¾ç½®éšæœºç§å­
np.random.seed(42)
torch.manual_seed(42)

print("ç¯å¢ƒè®¾ç½®å®Œæˆ")
print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")`,
    outputs: [
      `ç¯å¢ƒè®¾ç½®å®Œæˆ
PyTorch ç‰ˆæœ¬: 2.1.0
CUDA å¯ç”¨: True`
    ],
    executionCount: 1
  },
  {
    type: 'code' as const,
    source: `# åŠ è½½è®­ç»ƒæ—¥å¿—æ•°æ®
training_logs = pd.read_csv('rlhf_training_logs.csv')

print(f"è®­ç»ƒæ—¥å¿—å½¢çŠ¶: {training_logs.shape}")
print("\\nå‰5è¡Œæ•°æ®:")
print(training_logs.head())

print("\\næ•°æ®åˆ—ä¿¡æ¯:")
print(training_logs.info())`,
    outputs: [
      `è®­ç»ƒæ—¥å¿—å½¢çŠ¶: (1000, 8)

å‰5è¡Œæ•°æ®:
   step  policy_loss  value_loss  kl_divergence  reward_score  learning_rate  batch_size        timestamp
0     1      2.45123     1.82345       0.123456      -0.234567         3e-05          16  2024-01-15 10:00:01
1     2      2.43876     1.80123       0.125789      -0.221345         3e-05          16  2024-01-15 10:00:32
2     3      2.42654     1.79001       0.127234      -0.208902         3e-05          16  2024-01-15 10:01:03
3     4      2.41432     1.77889       0.128567      -0.196734         3e-05          16  2024-01-15 10:01:34
4     5      2.40213     1.76778       0.129890      -0.184567         3e-05          16  2024-01-15 10:02:05

æ•°æ®åˆ—ä¿¡æ¯:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 8 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   step           1000 non-null   int64  
 1   policy_loss    1000 non-null   float64
 2   value_loss     1000 non-null   float64
 3   kl_divergence  1000 non-null   float64
 4   reward_score   1000 non-null   float64
 5   learning_rate  1000 non-null   object 
 6   batch_size     1000 non-null   int64  
 7   timestamp      1000 non-null   object 
dtypes: float64(4), int64(2), object(2)
memory usage: 62.6+ KB`
    ],
    executionCount: 2
  },
  {
    type: 'code' as const,
    source: `# ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿
plt.figure(figsize=(15, 10))

# åˆ›å»ºå­å›¾
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('RLHF è®­ç»ƒç›‘æ§é¢æ¿', fontsize=16, fontweight='bold')

# ç­–ç•¥æŸå¤±
axes[0, 0].plot(training_logs['step'], training_logs['policy_loss'], 
               color='blue', linewidth=2, alpha=0.8)
axes[0, 0].set_title('ç­–ç•¥æŸå¤± (Policy Loss)')
axes[0, 0].set_xlabel('è®­ç»ƒæ­¥æ•°')
axes[0, 0].set_ylabel('æŸå¤±å€¼')
axes[0, 0].grid(True, alpha=0.3)

# ä»·å€¼æŸå¤±
axes[0, 1].plot(training_logs['step'], training_logs['value_loss'], 
               color='red', linewidth=2, alpha=0.8)
axes[0, 1].set_title('ä»·å€¼æŸå¤± (Value Loss)')
axes[0, 1].set_xlabel('è®­ç»ƒæ­¥æ•°')
axes[0, 1].set_ylabel('æŸå¤±å€¼')
axes[0, 1].grid(True, alpha=0.3)

# KLæ•£åº¦
axes[1, 0].plot(training_logs['step'], training_logs['kl_divergence'], 
               color='green', linewidth=2, alpha=0.8)
axes[1, 0].set_title('KLæ•£åº¦ (KL Divergence)')
axes[1, 0].set_xlabel('è®­ç»ƒæ­¥æ•°')
axes[1, 0].set_ylabel('KLæ•£åº¦å€¼')
axes[1, 0].grid(True, alpha=0.3)

# å¥–åŠ±åˆ†æ•°
axes[1, 1].plot(training_logs['step'], training_logs['reward_score'], 
               color='purple', linewidth=2, alpha=0.8)
axes[1, 1].set_title('å¥–åŠ±åˆ†æ•° (Reward Score)')
axes[1, 1].set_xlabel('è®­ç»ƒæ­¥æ•°')
axes[1, 1].set_ylabel('å¥–åŠ±å€¼')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# æ‰“å°è®­ç»ƒç»Ÿè®¡
print("\\nè®­ç»ƒç»Ÿè®¡ä¿¡æ¯:")
print(f"æœ€ç»ˆç­–ç•¥æŸå¤±: {training_logs['policy_loss'].iloc[-1]:.4f}")
print(f"æœ€ç»ˆä»·å€¼æŸå¤±: {training_logs['value_loss'].iloc[-1]:.4f}")
print(f"æœ€ç»ˆKLæ•£åº¦: {training_logs['kl_divergence'].iloc[-1]:.6f}")
print(f"æœ€ç»ˆå¥–åŠ±åˆ†æ•°: {training_logs['reward_score'].iloc[-1]:.4f}")`,
    outputs: [
      `è®­ç»ƒç»Ÿè®¡ä¿¡æ¯:
æœ€ç»ˆç­–ç•¥æŸå¤±: 1.2345
æœ€ç»ˆä»·å€¼æŸå¤±: 0.8901
æœ€ç»ˆKLæ•£åº¦: 0.234567
æœ€ç»ˆå¥–åŠ±åˆ†æ•°: 0.567891`
    ],
    executionCount: 3
  },
  {
    type: 'markdown' as const,
    source: `## å®éªŒç»“æœåˆ†æ

ä»ä¸Šé¢çš„è®­ç»ƒæ›²çº¿å¯ä»¥çœ‹å‡ºï¼š

1. **ç­–ç•¥æŸå¤±**ï¼šä»åˆå§‹çš„ 2.45 é€æ¸ä¸‹é™åˆ° 1.23ï¼Œæ˜¾ç¤ºæ¨¡å‹åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­é€æ­¥ä¼˜åŒ–
2. **ä»·å€¼æŸå¤±**ï¼šå‘ˆç°ç¨³å®šçš„ä¸‹é™è¶‹åŠ¿ï¼Œä» 1.82 é™è‡³ 0.89
3. **KLæ•£åº¦**ï¼šä¿æŒåœ¨åˆç†èŒƒå›´å†…ï¼ˆ< 0.3ï¼‰ï¼Œè¯´æ˜æ¨¡å‹æ²¡æœ‰åç¦»åˆå§‹ç­–ç•¥å¤ªè¿œ
4. **å¥–åŠ±åˆ†æ•°**ï¼šä»è´Ÿå€¼é€æ¸ä¸Šå‡åˆ°æ­£å€¼ï¼Œè¡¨æ˜æ¨¡å‹è¾“å‡ºè´¨é‡åœ¨æå‡

### å…³é”®è§‚å¯Ÿ
- è®­ç»ƒè¿‡ç¨‹ç¨³å®šï¼Œæ²¡æœ‰å‡ºç°å´©æºƒç°è±¡
- KLæ•£åº¦æ§åˆ¶è‰¯å¥½ï¼Œé¿å…äº†è¿‡åº¦ä¼˜åŒ–
- å¥–åŠ±åˆ†æ•°çš„æå‡éªŒè¯äº† RLHF çš„æœ‰æ•ˆæ€§`,
    executionCount: null
  },
  {
    type: 'code' as const,
    source: `# è®¡ç®—è®­ç»ƒæ•ˆç‡æŒ‡æ ‡
def calculate_training_metrics(logs):
    """è®¡ç®—è®­ç»ƒæ•ˆç‡ç›¸å…³æŒ‡æ ‡"""
    
    # æŸå¤±ä¸‹é™ç‡
    initial_policy_loss = logs['policy_loss'].iloc[0]
    final_policy_loss = logs['policy_loss'].iloc[-1]
    policy_loss_reduction = (initial_policy_loss - final_policy_loss) / initial_policy_loss * 100
    
    # å¥–åŠ±æ”¹è¿›å¹…åº¦
    initial_reward = logs['reward_score'].iloc[0]
    final_reward = logs['reward_score'].iloc[-1]
    reward_improvement = final_reward - initial_reward
    
    # è®­ç»ƒç¨³å®šæ€§ï¼ˆæŸå¤±æ–¹å·®ï¼‰
    policy_loss_variance = logs['policy_loss'].var()
    
    return {
        'policy_loss_reduction_pct': policy_loss_reduction,
        'reward_improvement': reward_improvement,
        'training_stability': 1.0 / (1.0 + policy_loss_variance)  # è¶Šå¤§è¶Šç¨³å®š
    }

metrics = calculate_training_metrics(training_logs)

print("ğŸ“Š è®­ç»ƒæ•ˆç‡æŒ‡æ ‡:")
print("=" * 40)
print(f"ç­–ç•¥æŸå¤±ä¸‹é™: {metrics['policy_loss_reduction_pct']:.2f}%")
print(f"å¥–åŠ±æ”¹è¿›å¹…åº¦: {metrics['reward_improvement']:.4f}")
print(f"è®­ç»ƒç¨³å®šæ€§: {metrics['training_stability']:.4f}")

# ç»˜åˆ¶ç§»åŠ¨å¹³å‡å›¾
window_size = 50
training_logs['policy_loss_ma'] = training_logs['policy_loss'].rolling(window=window_size).mean()
training_logs['reward_score_ma'] = training_logs['reward_score'].rolling(window=window_size).mean()

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(training_logs['step'], training_logs['policy_loss'], alpha=0.3, color='blue', label='åŸå§‹æ•°æ®')
plt.plot(training_logs['step'], training_logs['policy_loss_ma'], color='blue', linewidth=2, label=f'{window_size}æ­¥ç§»åŠ¨å¹³å‡')
plt.title('ç­–ç•¥æŸå¤±è¶‹åŠ¿')
plt.xlabel('è®­ç»ƒæ­¥æ•°')
plt.ylabel('æŸå¤±å€¼')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(training_logs['step'], training_logs['reward_score'], alpha=0.3, color='purple', label='åŸå§‹æ•°æ®')
plt.plot(training_logs['step'], training_logs['reward_score_ma'], color='purple', linewidth=2, label=f'{window_size}æ­¥ç§»åŠ¨å¹³å‡')
plt.title('å¥–åŠ±åˆ†æ•°è¶‹åŠ¿')
plt.xlabel('è®­ç»ƒæ­¥æ•°')
plt.ylabel('å¥–åŠ±å€¼')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()`,
    outputs: [
      `ğŸ“Š è®­ç»ƒæ•ˆç‡æŒ‡æ ‡:
========================================
ç­–ç•¥æŸå¤±ä¸‹é™: 49.67%
å¥–åŠ±æ”¹è¿›å¹…åº¦: 0.8024
è®­ç»ƒç¨³å®šæ€§: 0.8756`
    ],
    executionCount: 4
  },
  {
    type: 'markdown' as const,
    source: `## æ€»ç»“ä¸åç»­å·¥ä½œ

æœ¬æ¬¡ RLHF å®éªŒå–å¾—äº†è‰¯å¥½çš„æ•ˆæœï¼š

### æˆåŠŸæŒ‡æ ‡
- âœ… ç­–ç•¥æŸå¤±ä¸‹é™è¿‘ 50%
- âœ… å¥–åŠ±åˆ†æ•°æ˜¾è‘—æå‡
- âœ… è®­ç»ƒè¿‡ç¨‹ç¨³å®šï¼Œæ— å´©æºƒç°è±¡
- âœ… KLæ•£åº¦æ§åˆ¶åœ¨åˆç†èŒƒå›´

### ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘
1. **è¶…å‚æ•°è°ƒä¼˜**: å°è¯•ä¸åŒçš„å­¦ä¹ ç‡å’Œ KL ç³»æ•°
2. **æ•°æ®å¢å¼º**: å¢åŠ æ›´å¤šé«˜è´¨é‡çš„åå¥½æ•°æ®
3. **æ¨¡å‹è§„æ¨¡**: æµ‹è¯•æ›´å¤§è§„æ¨¡çš„æ¨¡å‹ï¼ˆå¦‚ GPT-2 Mediumï¼‰
4. **è¯„ä¼°ä¼˜åŒ–**: æ·»åŠ æ›´å¤šç»´åº¦çš„è¯„ä¼°æŒ‡æ ‡

### ä»£ç å’Œæ•°æ®
- å®Œæ•´å®éªŒä»£ç å·²ä¸Šä¼ åˆ° GitHub
- è®­ç»ƒæ—¥å¿—å’Œæ£€æŸ¥ç‚¹å·²ä¿å­˜åˆ° WandB
- å¯å¤ç°çš„å®éªŒç¯å¢ƒé…ç½®åœ¨ Docker é•œåƒä¸­`,
    executionCount: null
  }
];
---

<BaseLayout 
  title={notebook.data.title}
  description={notebook.data.description}
  keywords={notebook.data.tags}
>
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-12">
    <!-- Notebook Meta Info -->
    <div class="mb-8 text-center">
      <div class="flex items-center justify-center space-x-4 text-sm text-gray-600 mb-4">
        <time datetime={notebook.data.publishDate.toISOString()}>
          {notebook.data.publishDate.toLocaleDateString('zh-CN', {
            year: 'numeric',
            month: 'long',
            day: 'numeric'
          })}
        </time>
        <span>â€¢</span>
        <span>{notebook.data.author}</span>
        {notebook.data.tags.length > 0 && (
          <>
            <span>â€¢</span>
            <div class="flex flex-wrap gap-2">
              {notebook.data.tags.slice(0, 3).map((tag) => (
                <span class="bg-blue-100 text-blue-800 px-2 py-1 rounded text-xs">
                  {tag}
                </span>
              ))}
            </div>
          </>
        )}
      </div>
    </div>

    <!-- Notebook Viewer -->
    <SimpleNotebookViewer 
      cells={sampleNotebookCells}
      title={notebook.data.title}
      kernelName="Python 3 (RLHF Environment)"
    />

    <!-- Navigation -->
    <nav class="mt-12 pt-8 border-t border-gray-200">
      <div class="flex justify-between items-center">
        <a href="/notebooks" class="text-blue-600 hover:text-blue-700 font-medium flex items-center">
          <svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 19l-7-7m0 0l7-7m-7 7h18"></path>
          </svg>
          è¿”å› Notebooks åˆ—è¡¨
        </a>
        <div class="flex space-x-4">
          <button class="text-gray-600 hover:text-gray-900 flex items-center" onclick="window.print()">
            <svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 17h2a2 2 0 002-2v-4a2 2 0 00-2-2H5a2 2 0 00-2 2v4a2 2 0 002 2h2m2 4h6a2 2 0 002-2v-4a2 2 0 00-2-2H9a2 2 0 00-2 2v4a2 2 0 002 2zm8-12V5a2 2 0 00-2-2H9a2 2 0 00-2 2v4h10z"></path>
            </svg>
            æ‰“å°
          </button>
          <a href="#" class="text-gray-600 hover:text-gray-900 flex items-center">
            <svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8.684 13.342C8.886 12.938 9 12.482 9 12c0-.482-.114-.938-.316-1.342m0 2.684a3 3 0 110-2.684m0 2.684l6.632 3.316m-6.632-6l6.632-3.316m0 0a3 3 0 105.367-2.684 3 3 0 00-5.367 2.684zm0 9.316a3 3 0 105.367 2.684 3 3 0 00-5.367-2.684z"></path>
            </svg>
            åˆ†äº«
          </a>
        </div>
      </div>
    </nav>
  </div>
</BaseLayout>